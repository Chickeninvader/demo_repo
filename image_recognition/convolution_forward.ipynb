{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "\n",
        "    s = np.multiply(a_slice_prev, W)\n",
        "    Z = np.sum(s)\n",
        "    Z = Z + float(b)\n",
        "\n",
        "    return Z\n",
        "\n",
        "def conv_forward_example(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, \n",
        "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "\n",
        "    # Take parameters and initialize\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    f, f, n_C_prev, n_C = W.shape\n",
        "    stride = hparameters[\"stride\"]\n",
        "    pad = hparameters['pad']\n",
        "    n_H = int((n_H_prev+2*pad-f)/stride + 1)\n",
        "    n_W = int((n_W_prev+2*pad-f)/stride + 1)\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "\n",
        "    A_prev_pad = np.pad(A_prev, ((0,0), (pad,pad), (pad,pad), (0,0)), mode='constant', constant_values = (0,0))\n",
        "    \n",
        "    for i in range(m):               \n",
        "        a_prev_pad = A_prev_pad[i,:,:,:]                \n",
        "        for h in range(n_H):           \n",
        "            vert_start = h*stride\n",
        "            vert_end = h*stride+f\n",
        "            for w in range(n_W):       \n",
        "                horiz_start = w*stride\n",
        "                horiz_end = w*stride+f\n",
        "                for c in range(n_C):   \n",
        "\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end,:]\n",
        "                    weights = W[:,:,:,c]\n",
        "                    biases = b[:,:,:,c]\n",
        "\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
        "            \n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache\n",
        "\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "\n",
        "    \"\"\"\n",
        "    Implements the forward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(0,n_H, stride):         # loop on the vertical axis of the output volume\n",
        "            vert_start = h\n",
        "            vert_end = h+f\n",
        "            \n",
        "            for w in range(0,n_W, stride):                 # loop on the horizontal axis of the output volume\n",
        "                horiz_start = w\n",
        "                horiz_end = w+f\n",
        "                \n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]  \n",
        "                    \n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "\n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    return A, cache\n",
        "\n",
        "def conv_forward_multiple_examples(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function through m examples\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, \n",
        "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (m, f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (m, 1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function (A_prev, W, b, hparameters)\n",
        "    \"\"\"\n",
        "    # initialize\n",
        "    m = A_prev.shape[0]\n",
        "    Z = [None] * m\n",
        "    cache = [None]* m \n",
        "    for i in range(m):\n",
        "        W_example = W[i,:,:,:,:]\n",
        "        b_example = b[i,:,:,:,:]\n",
        "        Z[i], _ = conv_forward_example(A_prev, W_example, b_example, hparameters)\n",
        "\n",
        "    A = np.array(Z[i])\n",
        "    print(A.shape)\n",
        "    cache_update = (A_prev, W, b, hparameters)\n",
        "    return A, cache_update"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}